version: '3.9'

services:
  flask:
    build: ./flask
    environment:
      # OPTION: if torchserve is not running, this must be kept to "true". This turns off the polling for available models
      MOCK_ML_MODELS: "false"
      POSTGRES_DB_URL: "postgresql://postgres:postgres@postgres:5432/"
      # TODO: supply your flask secret key here; generate a long random string and paste it here
      FLASK_SECRET_KEY: "[YOUR_SECRET_KEY]"
      ETHERPAD_API_URL: "http://etherpad:9001/api"
      # TODO: set this to the domain where you will be running your etherpad instance. To be reliable,
      # it should be on the same domain as the Flask frontend to enable iframing of the editor.
      ETHERPAD_URL: "[YOUR_ETHERPAD_URL]"
      TORCHSERVE_MANAGEMENT_URL: "http://torchserve:8085"
      PYTHONBUFFERED: 1
    command: gunicorn main:app -w 2 --threads 2 -b 0.0.0.0:7777 --timeout 3600 --log-level info
    restart: always
    volumes:
      - /SOME_LOCAL_FOLDER_FOR_STORING_AUDIO_DATA:/audio
    depends_on:
      - rabbitmq
      - postgres
    # OPTION: set the running port for the application.
    ports:
      - 7777:7777

  trsc-worker:
    build: ./transcription_worker
    environment:
      # OPTION: you can select a more or less powerful model here if needed and possible with your hardware
      WHISPER_MODEL: "large-v3"
    command: python transcription_worker.py
    restart: always
    depends_on:
      - rabbitmq
      - translation-worker
    volumes:
      - /SOME_LOCAL_WHISPER_MODEL_FOLDER:/whisper_model
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              
    translation-worker:
    build: ./translation_worker
    environment:
      MOCK_ML_MODELS: "false"
      CT_MODEL_PATH: "/nllb-200-600M-int8"
      SP_MODEL_PATH: "/flores200_sacrebleu_tokenizer_spm.model"
      PYTHONBUFFERED: 1
      DATA_FOLDER_PATH: "/minuteman_data"
    command: gunicorn main:app -w 1 --threads 1 -b 0.0.0.0:7778 --timeout 3600 --log-level info
    restart: always
    # OPTION: mount the model and tokenizer files
    volumes:
      - /SOME_LOCAL_NLLB_MODEL_FOLDER/nllb-200-600M-int8:/nllb-200-600M-int8
      - /SOME_LOCAL_NLLB_MODEL_FOLDER/flores200_sacrebleu_tokenizer_spm.model:/flores200_sacrebleu_tokenizer_spm.model
      - /SOME_LOCAL_WHISPER_MODEL_FOLDER:/whisper_model
      - /SOME_LOCAL_DATA_FOLDER:/minuteman_data
    # OPTION: set the running port for the application.
    ports:
      - 7778:7778
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0", "1"]
              capabilities: [gpu]

  summ-worker:
    build: ./summarization_worker
    environment:
      # OPTION: when set to true, this replaces requests to torchserve models with a mock string
      PYTHONBUFFERED: 1
      MOCK_ML_MODELS: "false"
      TORCH_BACKEND_URL: "http://torchserve:8084"
    command: python summarization_worker.py
    restart: always
    depends_on:
      - rabbitmq
      - translation-worker

  torchserve:
    build: ./torchserve
    # OPTION: you can provide additional models here if you created them
    command: torchserve --ts-config /torch-config.cnf --model-store /torch_model_dir --models bart=lidiya-bart.mar --log-config /torchserve-log4j2.xml --start
    volumes:
     - ./torch_model_dir:/torch_model_dir
     - ./torch-config.cnf:/torch-config.cnf
     - ./torchserve-log4j2.xml:/torchserve-log4j2.xml
    deploy:
      resources:
        reservations:
         devices:
           - driver: nvidia
             device_ids: ["1"]
             capabilities: [gpu]

  postgres:
    image: postgres:15-alpine
    restart: always
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      PGDATA: /var/lib/postgresql/data/pgdata
    volumes:
      - pgdata:/var/lib/postgresql/data
      - ./flask/db/create_db.sql:/docker-entrypoint-initdb.d/create_tables.sql
    command: ["postgres", "-c", "log_statement=none", "-c", "log_checkpoints=off"]

  etherpad:
    build: ./etherpad-lite
    ports:
      - 9001:9001
    environment:
      TITLE: Minuteman
      # TODO: set the Etherpad admin password
      ADMIN_PASSWORD: "YOUR ADMIN PASSWORD"
      ADMIN_USER: admin
      DB_TYPE: postgres
      DB_HOST: postgres
      DB_PORT: 5432
      DB_USER: postgres
      DB_PASS: postgres
      DB_NAME: postgres
      DB_CHARSET: utf8mb4
    restart: no
    depends_on:
      - postgres
      - rabbitmq
    volumes:
      - plugins:/opt/etherpad-lite/src/plugin_packages
      - etherpad-var:/opt/etherpad-lite/var

  rabbitmq:
    build: ./rabbitmq
    image: rabbitmq
    volumes:
      - ./rabbitmq:/var/lib/rabbitmq
    # OPTION: rabbitMQ ports are forwarded to the host by default, as it is often the case that you want to stream a transcript into the editor from an external script
    ports:
      - 5672:5672
      - 15672:15672

volumes:
  pgdata:
  plugins:
  etherpad-var:
